{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO33sEwIoPlDx2Nj0jhAodT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Set up a local environment"],"metadata":{"id":"d2NPmAZTszkW"}},{"cell_type":"markdown","source":["## Create an Elastic Stack with `start-local`\n","\n","You can run this workshop in three different ways:\n","\n","* Run a Elastic stack (Elasticsearch & Kibana) on your computer\n","* Using an Elastic stack deployment in [Elastic Cloud](https://cloud.elastic.co) or anywhere else\n","* With an [Elastic Serverless project](https://www.elastic.co/docs/deploy-manage/deploy/elastic-cloud/serverless)\n","\n","The following instructions set up a local environment with Elasticsearch and Kibana.\n","\n","Create a new folder and inside execute the following commands to download the `start-local` script and execute it:\n","\n","```bash\n","curl -fsSL https://elastic.co/start-local > start-local\n","bash start-local -v 9.0.3\n","```\n","\n","For more details about `start-local` refer to the [README on GitHub](https://github.com/elastic/start-local).\n","\n","You'll see how images are downloaded, volumes and containers created, etc. An output like this will be rendered at the end of the execution:\n","\n","```text\n","üéâ Congrats, Elasticsearch and Kibana are installed and running in Docker!\n","\n","üåê Open your browser at http://localhost:5601\n","\n","   Username: elastic\n","   Password: hODGZcFs\n","\n","üîå Elasticsearch API endpoint: http://localhost:9200\n","üîë API key: OThOSDJwY0I3QnlxdzlfMnVtZTc6TDlSUlpCVjRoQXdvb0oyODVNaVFEUQ==\n","\n","Learn more at https://github.com/elastic/start-local\n","```\n","\n","Copy the login details from the command output:\n","\n","* User and password\n","* API key\n","\n","\n","## Add a Jupyterlab notebook environment\n","\n","Now you can add the following code to the `elastic-start-local/docker-compose.yml` file,\n","just after the Kibana service is defined and before the `volumes` key.\n","\n","```yaml\n","  notebook:\n","    depends_on:\n","      elasticsearch:\n","        condition: service_healthy\n","      kibana:\n","        condition: service_healthy\n","    image: quay.io/jupyter/base-notebook\n","    volumes:\n","      - ../lab:/lab\n","    ports:\n","      - 127.0.0.1:8888:8888\n","    environment:\n","      - ES_URL=${ES_URL}\n","      - KB_URL=${KB_URL}\n","      - ES_APIKEY=${ES_APIKEY}\n","    command: start-notebook.py --NotebookApp.token='elastic'\n","```\n","\n","And the new required environment variables in the `elastic-start-local/.env` file:\n","\n","```ini\n","# local\n","ES_URL=http://elasticsearch:9200\n","KB_URL=http://kibana:${KIBANA_LOCAL_PORT}\n","ES_APIKEY=${ES_LOCAL_API_KEY}\n","```\n","\n","\n","Stop and start the services with the scripts provided in the `elastic-start-local` folder to get the Jupyterlab environment ready at\n","\n","## Check the Notebook and Kibana\n","\n","* Jupyterlab URL: <http://localhost:8888/lab?token=elastic>.\n","* Kibana URL: <http://localhost:5601>"],"metadata":{"id":"ZNKYf_jeuvf4"}},{"cell_type":"markdown","source":["# Using a separate Elastic stack or Elastic Serverless"],"metadata":{"id":"y_GCheg3uged"}},{"cell_type":"markdown","source":["Alternatively, if you want to use any other Elastic stack like a Elastic Cloud hosted environment you can run the notebooks from any Jupyter runtime (locally hosted, Google Colaboratory, etc.)."],"metadata":{"id":"FLFb0rAwu4Y2"}},{"cell_type":"code","source":[],"metadata":{"id":"4q11oakXu49S"},"execution_count":null,"outputs":[]}]}